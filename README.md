# ğŸ“Š Financial Data Extraction & Analysis System

AI-powered financial data extraction and analysis platform with multi-agent architecture, RAG-based querying, and automated business health monitoring.

## âœ¨ Features

### ğŸ¤– Multi-Agent System
- **Master Agent**: Intelligent task routing and orchestration
- **Ingestion Agent**: Process Excel, PDF, and CSV files
- **Query Agent**: Natural language queries using RAG
- **Analytics Agent**: Business health analysis and insights
- **Maintenance Agent**: Database management and optimization

### ğŸ“ˆ Core Capabilities
- **File Processing**: Excel, PDF, CSV with AI-powered metadata extraction
- **Semantic Search**: Vector-based search using OpenAI embeddings
- **SQL Generation**: Natural language to SQL conversion
- **Business Analytics**: Automated financial health checks
- **Trend Detection**: Revenue, cost, and profit trend analysis
- **Interactive Charts**: Plotly visualizations

### ğŸ” Advanced Features
- **Google Drive Integration**: Direct file upload from Google Drive
- **Duplicate Detection**: Content-based file versioning
- **Multi-sheet Processing**: Parallel processing for faster ingestion
- **Type-Safe Agents**: Pydantic-based validation

## ğŸš€ Quick Start

### Prerequisites
- Python 3.8+
- PostgreSQL database (Neon recommended)
- OpenRouter API key

### Installation

1. Clone the repository:
```bash
git clone https://github.com/YOUR_USERNAME/metadata-extraction-new.git
cd metadata-extraction-new
```

2. Install dependencies:
```bash
pip install -r requirements.txt
```

3. Set up environment variables:
```bash
cp .env.example .env
# Edit .env with your credentials
```

4. Run the application:
```bash
streamlit run app.py
```

## ğŸ”§ Configuration

Create a `.env` file with:

```env
DATABASE_URL=postgresql://user:password@host/database
OPENROUTER_API_KEY=your_openrouter_api_key
```

## ğŸ“– Usage

### File Ingestion
```python
from agents import MasterAgent

master = MasterAgent(db_url=DB_URL, openai_key=API_KEY)

task = master.create_task(
    task_type="ingest",
    payload={"file_path": "data.xlsx"}
)

response = master.execute(task)
```

### Natural Language Queries
```python
task = master.create_task(
    task_type="query",
    payload={"question": "What was total revenue in 2024?"}
)

response = master.execute(task)
print(response.result['answer'])
```

### Business Health Analysis
```python
task = master.create_task(
    task_type="analyze",
    payload={"sheet_info": {...}}
)

response = master.execute(task)
print(response.result['status'])  # Healthy/Warning/Risk
```

## ğŸ—ï¸ Architecture

```
metadata-extraction-new/
â”œâ”€â”€ agents/                 # Multi-agent system
â”‚   â”œâ”€â”€ base_agent.py      # Pydantic base classes
â”‚   â”œâ”€â”€ master_agent.py    # Orchestrator
â”‚   â”œâ”€â”€ ingestion_agent.py # File processing
â”‚   â”œâ”€â”€ query_agent.py     # RAG queries
â”‚   â”œâ”€â”€ analytics_agent.py # Business intelligence
â”‚   â””â”€â”€ maintenance_agent.py # Database ops
â”œâ”€â”€ ingest_excel.py        # Excel file processing
â”œâ”€â”€ ingest_pdf.py          # PDF processing
â”œâ”€â”€ ingest_structured.py   # CSV processing
â”œâ”€â”€ retrieval.py           # RAG pipeline
â”œâ”€â”€ analytics.py           # Business health logic
â”œâ”€â”€ cleanup.py             # Database cleanup
â”œâ”€â”€ app.py                 # Streamlit UI
â””â”€â”€ requirements.txt       # Dependencies
```

## ğŸ› ï¸ Tech Stack

- **Backend**: Python, PostgreSQL, pgvector
- **Frontend**: Streamlit
- **AI/ML**: OpenAI (via OpenRouter), embeddings
- **Data Processing**: Pandas, openpyxl, pypdf
- **Visualization**: Plotly
- **Type Safety**: Pydantic
- **Cloud**: Neon Database

## ğŸ“Š Database Schema

### files_metadata
- `file_id` (UUID)
- `file_name` (TEXT)
- `uploaded_at` (TIMESTAMP)
- `summary_embedding` (vector 3072)
- `keywords_embedding` (vector 3072)

### sheets_metadata
- `sheet_id` (UUID)
- `file_id` (UUID FK)
- `table_name` (TEXT)
- `summary_embedding` (vector 3072)
- `columns_metadata` (JSONB)

## ğŸ¤ Contributing

Contributions are welcome! Please:
1. Fork the repository
2. Create a feature branch
3. Commit your changes
4. Push to the branch
5. Open a Pull Request

## ğŸ“ License

MIT License - see LICENSE file for details

## ğŸ› Known Issues

- Vector dimension mismatch: Run `python fix_vector_dimensions.py` to fix
- Slow processing: Increase `max_workers` in `ingest_excel.py` line 706

## ğŸ”® Roadmap

- [ ] Add export agent for report generation
- [ ] Implement notification system
- [ ] Add data validation agent
- [ ] Support for more file formats
- [ ] Advanced anomaly detection
- [ ] Scheduled automated reports

## ğŸ“§ Contact

For questions or support, please open an issue on GitHub.

## ğŸ™ Acknowledgments

- OpenRouter for AI API access
- Neon for serverless PostgreSQL
- Streamlit for the amazing framework
